{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this notebook we'll load in the various policy results in desperate hope that we'll have something informative and insightful. From early look ins at the intermediate results, at least AIS learned something informative when the demographics were included when learning the representation and the learning rate was set to 1e-3... I'm holding my breath and crossing my fingers.... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_context('paper')\n",
    "sns.set_style('white')\n",
    "\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams.update({'font.size': 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ewma_vectorized(data, alpha, offset=None, dtype=None, order='C', out=None):\n",
    "    \"\"\"\n",
    "    Calculates the exponential moving average over a vector.\n",
    "    Will fail for large inputs.\n",
    "    :param data: Input data\n",
    "    :param alpha: scalar float in range (0,1)\n",
    "        The alpha parameter for the moving average.\n",
    "    :param offset: optional\n",
    "        The offset for the moving average, scalar. Defaults to data[0].\n",
    "    :param dtype: optional\n",
    "        Data type used for calculations. Defaults to float64 unless\n",
    "        data.dtype is float32, then it will use float32.\n",
    "    :param order: {'C', 'F', 'A'}, optional\n",
    "        Order to use when flattening the data. Defaults to 'C'.\n",
    "    :param out: ndarray, or None, optional\n",
    "        A location into which the result is stored. If provided, it must have\n",
    "        the same shape as the input. If not provided or `None`,\n",
    "        a freshly-allocated array is returned.\n",
    "    \"\"\"\n",
    "    data = np.array(data, copy=False)\n",
    "\n",
    "    if dtype is None:\n",
    "        if data.dtype == np.float32:\n",
    "            dtype = np.float32\n",
    "        else:\n",
    "            dtype = np.float64\n",
    "    else:\n",
    "        dtype = np.dtype(dtype)\n",
    "\n",
    "    if data.ndim > 1:\n",
    "        # flatten input\n",
    "        data = data.reshape(-1, order)\n",
    "\n",
    "    if out is None:\n",
    "        out = np.empty_like(data, dtype=dtype)\n",
    "    else:\n",
    "        assert out.shape == data.shape\n",
    "        assert out.dtype == dtype\n",
    "\n",
    "    if data.size < 1:\n",
    "        # empty input, return empty array\n",
    "        return out\n",
    "\n",
    "    if offset is None:\n",
    "        offset = data[0]\n",
    "\n",
    "    alpha = np.array(alpha, copy=False).astype(dtype, copy=False)\n",
    "\n",
    "    # scaling_factors -> 0 as len(data) gets large\n",
    "    # this leads to divide-by-zeros below\n",
    "    scaling_factors = np.power(1. - alpha, np.arange(data.size + 1, dtype=dtype),\n",
    "                               dtype=dtype)\n",
    "    # create cumulative sum array\n",
    "    np.multiply(data, (alpha * scaling_factors[-2]) / scaling_factors[:-1],\n",
    "                dtype=dtype, out=out)\n",
    "    np.cumsum(out, dtype=dtype, out=out)\n",
    "\n",
    "    # cumsums / scaling\n",
    "    out /= scaling_factors[-2::-1]\n",
    "\n",
    "    if offset != 0:\n",
    "        offset = np.array(offset, copy=False).astype(dtype, copy=False)\n",
    "        # add offsets\n",
    "        out += offset * scaling_factors[1:]\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, I'm going to go approach by approach to make sure that I've done this properly in terms of loading and aggregating things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_nums = [25, 32, 1234, 2020, 53]\n",
    "alpha_param = 0.10\n",
    "learning_rates = ['1e-05', '0.0001','0.001']\n",
    "pol_eval_file = 'dBCQ_policy_eval_l'\n",
    "storage_dir_TWK = '/scratch/ssd001/home/tkillian/ml4h2020_srl/results/'\n",
    "storage_dir_HZ = '/scratch/hdd001/home/haoran/ml4h2020_srl/results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder (AE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'ae'\n",
    "\n",
    "noDem_noCorr_dir = f'{arch}_noCntxt_s256_l1e-4_rand'\n",
    "yDem_noCorr_dir = f'{arch}_s64_l1e-4_rand'\n",
    "noDem_yCorr_dir = f'{arch}_corrConst_noCntxt_s32_l1e-4_rand'\n",
    "yDem_yCorr_dir = f'{arch}_corrConst_s64_l1e-4_rand'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_noDem_noCorr_pol_results = np.zeros((len(learning_rates),len(rand_nums), 1000))\n",
    "ae_yDem_noCorr_pol_results = np.zeros((len(learning_rates),len(rand_nums), 1000))\n",
    "ae_noDem_yCorr_pol_results = np.zeros((len(learning_rates),len(rand_nums), 1000))\n",
    "ae_yDem_yCorr_pol_results = np.zeros((len(learning_rates),len(rand_nums), 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in learning_rates:\n",
    "    for rn in rand_nums:\n",
    "        lr_idx = learning_rates.index(lr)\n",
    "        rn_idx = rand_nums.index(rn)\n",
    "        nDnC_file_name = storage_dir_TWK+noDem_noCorr_dir+f'{rn}_sepsis/{arch}_data/'+pol_eval_file+f'{lr}.npy'\n",
    "        yDnC_file_name = storage_dir_TWK+yDem_noCorr_dir+f'{rn}_sepsis/{arch}_data/'+pol_eval_file+f'{lr}.npy'\n",
    "        nDyC_file_name = storage_dir_TWK+noDem_yCorr_dir+f'{rn}_sepsis/{arch}_data/'+pol_eval_file+f'{lr}.npy'\n",
    "        yDyC_file_name = storage_dir_TWK+yDem_yCorr_dir+f'{rn}_sepsis/{arch}_data/'+pol_eval_file+f'{lr}.npy'\n",
    "        \n",
    "        ae_noDem_noCorr_pol_results[lr_idx, rn_idx,:] = ewma_vectorized(np.load(nDnC_file_name), alpha_param)\n",
    "        ae_yDem_noCorr_pol_results[lr_idx, rn_idx,:] = ewma_vectorized(np.load(yDnC_file_name), alpha_param)\n",
    "        ae_noDem_yCorr_pol_results[lr_idx, rn_idx,:] = ewma_vectorized(np.load(nDyC_file_name), alpha_param)\n",
    "        ae_yDem_yCorr_pol_results[lr_idx, rn_idx,:] = ewma_vectorized(np.load(yDyC_file_name), alpha_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette('CMRmap', n_colors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for lr_idx, lr in enumerate(learning_rates):\n",
    "    \n",
    "    temp_mean = np.mean(ae_yDem_noCorr_pol_results[lr_idx], axis=0)\n",
    "    temp_std = np.std(ae_yDem_noCorr_pol_results[lr_idx], axis=0)\n",
    "    \n",
    "    plt.plot(np.arange(1000), temp_mean, lw=2, color=colors[lr_idx], label=f'lr={lr}')\n",
    "    plt.fill_between(np.arange(1000),temp_mean - temp_std, temp_mean + temp_std, alpha=0.3, color=colors[lr_idx])\n",
    "plt.title(f'{arch.upper()} w/ Dem. w/o Corr')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for lr_idx, lr in enumerate(learning_rates):\n",
    "    \n",
    "    temp_mean = np.mean(ae_noDem_yCorr_pol_results[lr_idx], axis=0)\n",
    "    temp_std = np.std(ae_noDem_yCorr_pol_results[lr_idx], axis=0)\n",
    "    \n",
    "    plt.plot(np.arange(1000), temp_mean, lw=2, color=colors[lr_idx], label=f'lr={lr}')\n",
    "    plt.fill_between(np.arange(1000),temp_mean - temp_std, temp_mean + temp_std, alpha=0.3, color=colors[lr_idx])\n",
    "plt.title(f'{arch.upper()} w/o Dem. w/ Corr')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for lr_idx, lr in enumerate(learning_rates):\n",
    "    \n",
    "    temp_mean = np.mean(ae_yDem_yCorr_pol_results[lr_idx], axis=0)\n",
    "    temp_std = np.std(ae_yDem_yCorr_pol_results[lr_idx], axis=0)\n",
    "    \n",
    "    plt.plot(np.arange(1000), temp_mean, lw=2, color=colors[lr_idx], label=f'lr={lr}')\n",
    "    plt.fill_between(np.arange(1000),temp_mean - temp_std, temp_mean + temp_std, alpha=0.3, color=colors[lr_idx])\n",
    "plt.title(f'{arch.upper()} w/ Dem. w/ Corr')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for lr_idx, lr in enumerate(learning_rates):\n",
    "    \n",
    "    temp_mean = np.mean(ae_noDem_noCorr_pol_results[lr_idx], axis=0)\n",
    "    temp_std = np.std(ae_noDem_noCorr_pol_results[lr_idx], axis=0)\n",
    "    \n",
    "    plt.plot(np.arange(1000), temp_mean, lw=2, color=colors[lr_idx], label=f'lr={lr}')\n",
    "    plt.fill_between(np.arange(1000),temp_mean - temp_std, temp_mean + temp_std, alpha=0.3, color=colors[lr_idx])\n",
    "plt.title(f'{arch.upper()} w/o Dem. w/o Corr')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Autoencoder (and I suspect for all other approaches) it seems that a learning rate of 1e-3 is the right choice and all policies trained on data that was not constrained by the correlation coeff seem to be learning something :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_comp = sns.color_palette('tab10',n_colors=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the policies learned between different training settings with a learning rate of 1e-3\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "nDnC_mean, nDnC_std = np.mean(ae_noDem_noCorr_pol_results[-1], axis=0), np.std(ae_noDem_noCorr_pol_results[-1], axis=0)\n",
    "nDyC_mean, nDyC_std = np.mean(ae_noDem_yCorr_pol_results[-1], axis=0), np.std(ae_noDem_yCorr_pol_results[-1], axis=0)\n",
    "yDnC_mean, yDnC_std = np.mean(ae_yDem_noCorr_pol_results[-1], axis=0), np.std(ae_yDem_noCorr_pol_results[-1], axis=0)\n",
    "yDyC_mean, yDyC_std = np.mean(ae_yDem_yCorr_pol_results[-1], axis=0), np.std(ae_yDem_yCorr_pol_results[-1], axis=0)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, nDnC_mean, lw=3, color=colors_comp[0], label='Observations Only')\n",
    "plt.fill_between(np.arange(1000)*500, nDnC_mean-nDnC_std, nDnC_mean+nDnC_std, color=colors_comp[0], alpha=0.3)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, nDyC_mean, lw=3, color=colors_comp[1], label='Correlation Constrained')\n",
    "plt.fill_between(np.arange(1000)*500, nDyC_mean-nDyC_std, nDyC_mean+nDyC_std, color=colors_comp[1], alpha=0.3)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, yDnC_mean, lw=3, color=colors_comp[2], label='Demographics Included')\n",
    "plt.fill_between(np.arange(1000)*500, yDnC_mean-yDnC_std, yDnC_mean+yDnC_std, color=colors_comp[2], alpha=0.3)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, yDyC_mean, lw=3, color=colors_comp[3], label='Correlation Const. + Demographics Incl.')\n",
    "plt.fill_between(np.arange(1000)*500, yDyC_mean-yDyC_std, yDyC_mean+yDyC_std, color=colors_comp[3], alpha=0.3)\n",
    "\n",
    "plt.title(f'{arch.upper()} Policy Comparison between Training Settings', fontsize=18)\n",
    "plt.xlabel(\"Iterations\", fontsize=16)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.ylabel(\"WIS Return\", fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.ylim([0.2, 1.0])\n",
    "plt.ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0))\n",
    "plt.legend(loc=2,fontsize=14)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ae_pol_mean = np.copy(nDnC_mean)\n",
    "best_ae_pol_std = np.copy(nDnC_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximate Information State (AIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'ais'\n",
    "\n",
    "noDem_noCorr_dir = f'{arch}_noCntxt_s64_l5e-4_rand'\n",
    "yDem_noCorr_dir = f'{arch}_s64_l5e-4_rand'\n",
    "noDem_yCorr_dir = f'{arch}_corrConst_noCntxt_s64_l5e-4_rand'\n",
    "yDem_yCorr_dir = f'{arch}_corrConst_s64_l5e-4_rand'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ais_noDem_noCorr_pol_results = np.zeros((len(learning_rates),len(rand_nums), 1000))\n",
    "ais_yDem_noCorr_pol_results = np.zeros((len(learning_rates),len(rand_nums), 1000))\n",
    "ais_noDem_yCorr_pol_results = np.zeros((len(learning_rates),len(rand_nums), 1000))\n",
    "ais_yDem_yCorr_pol_results = np.zeros((len(learning_rates),len(rand_nums), 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in learning_rates:\n",
    "    for rn in rand_nums:\n",
    "        lr_idx = learning_rates.index(lr)\n",
    "        rn_idx = rand_nums.index(rn)\n",
    "        nDnC_file_name = storage_dir_TWK+noDem_noCorr_dir+f'{rn}_sepsis/{arch}_data/'+pol_eval_file+f'{lr}.npy'\n",
    "        yDnC_file_name = storage_dir_TWK+yDem_noCorr_dir+f'{rn}_sepsis/{arch}_data/'+pol_eval_file+f'{lr}.npy'\n",
    "        nDyC_file_name = storage_dir_TWK+noDem_yCorr_dir+f'{rn}_sepsis/{arch}_data/'+pol_eval_file+f'{lr}.npy'\n",
    "        yDyC_file_name = storage_dir_TWK+yDem_yCorr_dir+f'{rn}_sepsis/{arch}_data/'+pol_eval_file+f'{lr}.npy'\n",
    "        \n",
    "        ais_noDem_noCorr_pol_results[lr_idx, rn_idx,:] = ewma_vectorized(np.load(nDnC_file_name), alpha_param)\n",
    "        ais_yDem_noCorr_pol_results[lr_idx, rn_idx,:] = ewma_vectorized(np.load(yDnC_file_name), alpha_param)\n",
    "        ais_noDem_yCorr_pol_results[lr_idx, rn_idx,:] = ewma_vectorized(np.load(nDyC_file_name), alpha_param)\n",
    "        ais_yDem_yCorr_pol_results[lr_idx, rn_idx,:] = ewma_vectorized(np.load(yDyC_file_name), alpha_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for lr_idx, lr in enumerate(learning_rates):\n",
    "    \n",
    "    temp_mean = np.mean(ais_yDem_noCorr_pol_results[lr_idx], axis=0)\n",
    "    temp_std = np.std(ais_yDem_noCorr_pol_results[lr_idx], axis=0)\n",
    "    \n",
    "    plt.plot(np.arange(1000), temp_mean, lw=2, color=colors[lr_idx], label=f'lr={lr}')\n",
    "    plt.fill_between(np.arange(1000),temp_mean - temp_std, temp_mean + temp_std, alpha=0.3, color=colors[lr_idx])\n",
    "plt.title(f'{arch.upper()} w/ Dem. w/o Corr')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for lr_idx, lr in enumerate(learning_rates):\n",
    "    \n",
    "    temp_mean = np.mean(ais_noDem_yCorr_pol_results[lr_idx], axis=0)\n",
    "    temp_std = np.std(ais_noDem_yCorr_pol_results[lr_idx], axis=0)\n",
    "    \n",
    "    plt.plot(np.arange(1000), temp_mean, lw=2, color=colors[lr_idx], label=f'lr={lr}')\n",
    "    plt.fill_between(np.arange(1000),temp_mean - temp_std, temp_mean + temp_std, alpha=0.3, color=colors[lr_idx])\n",
    "plt.title(f'{arch.upper()} w/o Dem. w/ Corr')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for lr_idx, lr in enumerate(learning_rates):\n",
    "    \n",
    "    temp_mean = np.mean(ais_yDem_yCorr_pol_results[lr_idx], axis=0)\n",
    "    temp_std = np.std(ais_yDem_yCorr_pol_results[lr_idx], axis=0)\n",
    "    \n",
    "    plt.plot(np.arange(1000), temp_mean, lw=2, color=colors[lr_idx], label=f'lr={lr}')\n",
    "    plt.fill_between(np.arange(1000),temp_mean - temp_std, temp_mean + temp_std, alpha=0.3, color=colors[lr_idx])\n",
    "plt.title(f'{arch.upper()} w/ Dem. w/ Corr')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for lr_idx, lr in enumerate(learning_rates):\n",
    "    \n",
    "    temp_mean = np.mean(ais_noDem_noCorr_pol_results[lr_idx], axis=0)\n",
    "    temp_std = np.std(ais_noDem_noCorr_pol_results[lr_idx], axis=0)\n",
    "    \n",
    "    plt.plot(np.arange(1000), temp_mean, lw=2, color=colors[lr_idx], label=f'lr={lr}')\n",
    "    plt.fill_between(np.arange(1000),temp_mean - temp_std, temp_mean + temp_std, alpha=0.3, color=colors[lr_idx])\n",
    "plt.title(f'{arch.upper()} w/o Dem. w/o Corr')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the policies learned between different training settings with a learning rate of 1e-3\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "nDnC_mean, nDnC_std = np.mean(ais_noDem_noCorr_pol_results[-1], axis=0), np.std(ais_noDem_noCorr_pol_results[-1], axis=0)\n",
    "nDyC_mean, nDyC_std = np.mean(ais_noDem_yCorr_pol_results[-1], axis=0), np.std(ais_noDem_yCorr_pol_results[-1], axis=0)\n",
    "yDnC_mean, yDnC_std = np.mean(ais_yDem_noCorr_pol_results[-1], axis=0), np.std(ais_yDem_noCorr_pol_results[-1], axis=0)\n",
    "yDyC_mean, yDyC_std = np.mean(ais_yDem_yCorr_pol_results[-1], axis=0), np.std(ais_yDem_yCorr_pol_results[-1], axis=0)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, nDnC_mean, lw=3, color=colors_comp[0], label='Observations Only')\n",
    "plt.fill_between(np.arange(1000)*500, nDnC_mean-nDnC_std, nDnC_mean+nDnC_std, color=colors_comp[0], alpha=0.3)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, nDyC_mean, lw=3, color=colors_comp[1], label='Correlation Constrained')\n",
    "plt.fill_between(np.arange(1000)*500, nDyC_mean-nDyC_std, nDyC_mean+nDyC_std, color=colors_comp[1], alpha=0.3)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, yDnC_mean, lw=3, color=colors_comp[2], label='Demographics Included')\n",
    "plt.fill_between(np.arange(1000)*500, yDnC_mean-yDnC_std, yDnC_mean+yDnC_std, color=colors_comp[2], alpha=0.3)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, yDyC_mean, lw=3, color=colors_comp[3], label='Correlation Const. + Demographics Incl.')\n",
    "plt.fill_between(np.arange(1000)*500, yDyC_mean-yDyC_std, yDyC_mean+yDyC_std, color=colors_comp[3], alpha=0.3)\n",
    "\n",
    "plt.title(f'{arch.upper()} Policy Comparison between Training Settings', fontsize=18)\n",
    "plt.xlabel(\"Iterations\", fontsize=16)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.ylabel(\"WIS Return\", fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.ylim([0.2, 1.0])\n",
    "plt.ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0))\n",
    "plt.legend(loc=2,fontsize=14)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ais_pol_mean = np.copy(yDnC_mean)\n",
    "best_ais_pol_std = np.copy(yDnC_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoupled Dynamics Module (DDM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'ddm'\n",
    "\n",
    "noDem_noCorr_dir = f'{arch}_noCntxt_s128_l1e-4_rand'\n",
    "yDem_noCorr_dir = f'{arch}_s128_l1e-4_rand'\n",
    "noDem_yCorr_dir = f'{arch}_corrConstp25_noCntxt_s256_l1e-4_rand'\n",
    "yDem_yCorr_dir = f'{arch}_corrConstp25_s256_l1e-4_rand'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddm_noDem_noCorr_pol_results = np.zeros((len(learning_rates),len(rand_nums), 1000))\n",
    "ddm_yDem_noCorr_pol_results = np.zeros((len(learning_rates),len(rand_nums), 1000))\n",
    "ddm_noDem_yCorr_pol_results = np.zeros((len(learning_rates),len(rand_nums), 1000))\n",
    "ddm_yDem_yCorr_pol_results = np.zeros((len(learning_rates),len(rand_nums), 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in learning_rates:\n",
    "    for rn in rand_nums:\n",
    "        lr_idx = learning_rates.index(lr)\n",
    "        rn_idx = rand_nums.index(rn)\n",
    "        nDnC_file_name = storage_dir_TWK+noDem_noCorr_dir+f'{rn}_sepsis/{arch}_data/'+pol_eval_file+f'{lr}.npy'\n",
    "        yDnC_file_name = storage_dir_TWK+yDem_noCorr_dir+f'{rn}_sepsis/{arch}_data/'+pol_eval_file+f'{lr}.npy'\n",
    "        nDyC_file_name = storage_dir_TWK+noDem_yCorr_dir+f'{rn}_sepsis/{arch}_data/'+pol_eval_file+f'{lr}.npy'\n",
    "        yDyC_file_name = storage_dir_TWK+yDem_yCorr_dir+f'{rn}_sepsis/{arch}_data/'+pol_eval_file+f'{lr}.npy'\n",
    "        \n",
    "        ddm_noDem_noCorr_pol_results[lr_idx, rn_idx,:] = ewma_vectorized(np.load(nDnC_file_name), alpha_param)\n",
    "        ddm_yDem_noCorr_pol_results[lr_idx, rn_idx,:] = ewma_vectorized(np.load(yDnC_file_name), alpha_param)\n",
    "        ddm_noDem_yCorr_pol_results[lr_idx, rn_idx,:] = ewma_vectorized(np.load(nDyC_file_name), alpha_param)\n",
    "        ddm_yDem_yCorr_pol_results[lr_idx, rn_idx,:] = ewma_vectorized(np.load(yDyC_file_name), alpha_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for lr_idx, lr in enumerate(learning_rates):\n",
    "    \n",
    "    temp_mean = np.mean(ddm_yDem_noCorr_pol_results[lr_idx], axis=0)\n",
    "    temp_std = np.std(ddm_yDem_noCorr_pol_results[lr_idx], axis=0)\n",
    "    \n",
    "    plt.plot(np.arange(1000), temp_mean, lw=2, color=colors[lr_idx], label=f'lr={lr}')\n",
    "    plt.fill_between(np.arange(1000),temp_mean - temp_std, temp_mean + temp_std, alpha=0.3, color=colors[lr_idx])\n",
    "plt.title(f'{arch.upper()} w/ Dem. w/o Corr')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for lr_idx, lr in enumerate(learning_rates):\n",
    "    \n",
    "    temp_mean = np.mean(ddm_noDem_yCorr_pol_results[lr_idx], axis=0)\n",
    "    temp_std = np.std(ddm_noDem_yCorr_pol_results[lr_idx], axis=0)\n",
    "    \n",
    "    plt.plot(np.arange(1000), temp_mean, lw=2, color=colors[lr_idx], label=f'lr={lr}')\n",
    "    plt.fill_between(np.arange(1000),temp_mean - temp_std, temp_mean + temp_std, alpha=0.3, color=colors[lr_idx])\n",
    "plt.title(f'{arch.upper()} w/o Dem. w/ Corr')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for lr_idx, lr in enumerate(learning_rates):\n",
    "    \n",
    "    temp_mean = np.mean(ddm_yDem_yCorr_pol_results[lr_idx], axis=0)\n",
    "    temp_std = np.std(ddm_yDem_yCorr_pol_results[lr_idx], axis=0)\n",
    "    \n",
    "    plt.plot(np.arange(1000), temp_mean, lw=2, color=colors[lr_idx], label=f'lr={lr}')\n",
    "    plt.fill_between(np.arange(1000),temp_mean - temp_std, temp_mean + temp_std, alpha=0.3, color=colors[lr_idx])\n",
    "plt.title(f'{arch.upper()} w/ Dem. w/ Corr')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for lr_idx, lr in enumerate(learning_rates):\n",
    "    \n",
    "    temp_mean = np.mean(ddm_noDem_noCorr_pol_results[lr_idx], axis=0)\n",
    "    temp_std = np.std(ddm_noDem_noCorr_pol_results[lr_idx], axis=0)\n",
    "    \n",
    "    plt.plot(np.arange(1000), temp_mean, lw=2, color=colors[lr_idx], label=f'lr={lr}')\n",
    "    plt.fill_between(np.arange(1000),temp_mean - temp_std, temp_mean + temp_std, alpha=0.3, color=colors[lr_idx])\n",
    "plt.title(f'{arch.upper()} w/o Dem. w/o Corr')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the policies learned between different training settings with a learning rate of 1e-3\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "nDnC_mean, nDnC_std = np.mean(ddm_noDem_noCorr_pol_results[-1], axis=0), np.std(ddm_noDem_noCorr_pol_results[-1], axis=0)\n",
    "nDyC_mean, nDyC_std = np.mean(ddm_noDem_yCorr_pol_results[-1], axis=0), np.std(ddm_noDem_yCorr_pol_results[-1], axis=0)\n",
    "yDnC_mean, yDnC_std = np.mean(ddm_yDem_noCorr_pol_results[-1], axis=0), np.std(ddm_yDem_noCorr_pol_results[-1], axis=0)\n",
    "yDyC_mean, yDyC_std = np.mean(ddm_yDem_yCorr_pol_results[-1], axis=0), np.std(ddm_yDem_yCorr_pol_results[-1], axis=0)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, nDnC_mean, lw=3, color=colors_comp[0], label='Observations Only')\n",
    "plt.fill_between(np.arange(1000)*500, nDnC_mean-nDnC_std, nDnC_mean+nDnC_std, color=colors_comp[0], alpha=0.3)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, nDyC_mean, lw=3, color=colors_comp[1], label='Correlation Constrained')\n",
    "plt.fill_between(np.arange(1000)*500, nDyC_mean-nDyC_std, nDyC_mean+nDyC_std, color=colors_comp[1], alpha=0.3)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, yDnC_mean, lw=3, color=colors_comp[2], label='Demographics Included')\n",
    "plt.fill_between(np.arange(1000)*500, yDnC_mean-yDnC_std, yDnC_mean+yDnC_std, color=colors_comp[2], alpha=0.3)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, yDyC_mean, lw=3, color=colors_comp[3], label='Correlation Const. + Demographics Incl.')\n",
    "plt.fill_between(np.arange(1000)*500, yDyC_mean-yDyC_std, yDyC_mean+yDyC_std, color=colors_comp[3], alpha=0.3)\n",
    "\n",
    "plt.title(f'{arch.upper()} Policy Comparison between Training Settings', fontsize=18)\n",
    "plt.xlabel(\"Iterations\", fontsize=16)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.ylabel(\"WIS Return\", fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.ylim([0.2, 1.0])\n",
    "plt.ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0))\n",
    "plt.legend(loc=2,fontsize=14)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ddm_pol_mean = np.copy(yDnC_mean)\n",
    "best_ddm_pol_std = np.copy(yDnC_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Signature Transform (DST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'dst'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_noDem_noCorr_pol_results = np.zeros((len(learning_rates),len(rand_nums), 1000))\n",
    "dst_yDem_noCorr_pol_results = np.zeros((len(learning_rates),len(rand_nums), 1000))\n",
    "dst_noDem_yCorr_pol_results = np.zeros((len(learning_rates),len(rand_nums), 1000))\n",
    "dst_yDem_yCorr_pol_results = np.zeros((len(learning_rates),len(rand_nums), 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in learning_rates:\n",
    "    for rn in rand_nums:\n",
    "        lr_idx = learning_rates.index(lr)\n",
    "        rn_idx = rand_nums.index(rn)\n",
    "        nDnC_file_name = storage_dir_HZ+f'{arch}/{arch}_sz64_rand{rn}_corr0_contextFalse_sepsis_training/{arch}_data/'+pol_eval_file+f'{lr}.npy'\n",
    "        yDnC_file_name = storage_dir_HZ+f'{arch}/{arch}_sz64_rand{rn}_corr0_contextTrue_sepsis_training/{arch}_data/'+pol_eval_file+f'{lr}.npy'\n",
    "        nDyC_file_name = storage_dir_HZ+f'{arch}/{arch}_sz64_rand{rn}_corr1_contextFalse_sepsis_training/{arch}_data/'+pol_eval_file+f'{lr}.npy'\n",
    "        yDyC_file_name = storage_dir_HZ+f'{arch}/{arch}_sz64_rand{rn}_corr1_contextTrue_sepsis_training/{arch}_data/'+pol_eval_file+f'{lr}.npy'\n",
    "        \n",
    "        dst_noDem_noCorr_pol_results[lr_idx, rn_idx,:] = ewma_vectorized(np.load(nDnC_file_name), alpha_param)\n",
    "        dst_yDem_noCorr_pol_results[lr_idx, rn_idx,:] = ewma_vectorized(np.load(yDnC_file_name), alpha_param)\n",
    "        dst_noDem_yCorr_pol_results[lr_idx, rn_idx,:] = ewma_vectorized(np.load(nDyC_file_name), alpha_param)\n",
    "        dst_yDem_yCorr_pol_results[lr_idx, rn_idx,:] = ewma_vectorized(np.load(yDyC_file_name), alpha_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for lr_idx, lr in enumerate(learning_rates):\n",
    "    \n",
    "    temp_mean = np.mean(dst_yDem_noCorr_pol_results[lr_idx], axis=0)\n",
    "    temp_std = np.std(dst_yDem_noCorr_pol_results[lr_idx], axis=0)\n",
    "    \n",
    "    plt.plot(np.arange(1000), temp_mean, lw=2, color=colors[lr_idx], label=f'lr={lr}')\n",
    "    plt.fill_between(np.arange(1000),temp_mean - temp_std, temp_mean + temp_std, alpha=0.3, color=colors[lr_idx])\n",
    "plt.title(f'{arch.upper()} w/ Dem. w/o Corr')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for lr_idx, lr in enumerate(learning_rates):\n",
    "    \n",
    "    temp_mean = np.mean(dst_noDem_yCorr_pol_results[lr_idx], axis=0)\n",
    "    temp_std = np.std(dst_noDem_yCorr_pol_results[lr_idx], axis=0)\n",
    "    \n",
    "    plt.plot(np.arange(1000), temp_mean, lw=2, color=colors[lr_idx], label=f'lr={lr}')\n",
    "    plt.fill_between(np.arange(1000),temp_mean - temp_std, temp_mean + temp_std, alpha=0.3, color=colors[lr_idx])\n",
    "plt.title(f'{arch.upper()} w/o Dem. w/ Corr')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for lr_idx, lr in enumerate(learning_rates):\n",
    "    \n",
    "    temp_mean = np.mean(dst_yDem_yCorr_pol_results[lr_idx], axis=0)\n",
    "    temp_std = np.std(dst_yDem_yCorr_pol_results[lr_idx], axis=0)\n",
    "    \n",
    "    plt.plot(np.arange(1000), temp_mean, lw=2, color=colors[lr_idx], label=f'lr={lr}')\n",
    "    plt.fill_between(np.arange(1000),temp_mean - temp_std, temp_mean + temp_std, alpha=0.3, color=colors[lr_idx])\n",
    "plt.title(f'{arch.upper()} w/ Dem. w/ Corr')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for lr_idx, lr in enumerate(learning_rates):\n",
    "    \n",
    "    temp_mean = np.mean(dst_noDem_noCorr_pol_results[lr_idx], axis=0)\n",
    "    temp_std = np.std(dst_noDem_noCorr_pol_results[lr_idx], axis=0)\n",
    "    \n",
    "    plt.plot(np.arange(1000), temp_mean, lw=2, color=colors[lr_idx], label=f'lr={lr}')\n",
    "    plt.fill_between(np.arange(1000),temp_mean - temp_std, temp_mean + temp_std, alpha=0.3, color=colors[lr_idx])\n",
    "plt.title(f'{arch.upper()} w/o Dem. w/o Corr')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the policies learned between different training settings with a learning rate of 1e-3\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "nDnC_mean, nDnC_std = np.mean(dst_noDem_noCorr_pol_results[-1], axis=0), np.std(dst_noDem_noCorr_pol_results[-1], axis=0)\n",
    "nDyC_mean, nDyC_std = np.mean(dst_noDem_yCorr_pol_results[-1], axis=0), np.std(dst_noDem_yCorr_pol_results[-1], axis=0)\n",
    "yDnC_mean, yDnC_std = np.mean(dst_yDem_noCorr_pol_results[-1], axis=0), np.std(dst_yDem_noCorr_pol_results[-1], axis=0)\n",
    "yDyC_mean, yDyC_std = np.mean(dst_yDem_yCorr_pol_results[-1], axis=0), np.std(dst_yDem_yCorr_pol_results[-1], axis=0)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, nDnC_mean, lw=3, color=colors_comp[0], label='Observations Only')\n",
    "plt.fill_between(np.arange(1000)*500, nDnC_mean-nDnC_std, nDnC_mean+nDnC_std, color=colors_comp[0], alpha=0.3)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, nDyC_mean, lw=3, color=colors_comp[1], label='Correlation Constrained')\n",
    "plt.fill_between(np.arange(1000)*500, nDyC_mean-nDyC_std, nDyC_mean+nDyC_std, color=colors_comp[1], alpha=0.3)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, yDnC_mean, lw=3, color=colors_comp[2], label='Demographics Included')\n",
    "plt.fill_between(np.arange(1000)*500, yDnC_mean-yDnC_std, yDnC_mean+yDnC_std, color=colors_comp[2], alpha=0.3)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, yDyC_mean, lw=3, color=colors_comp[3], label='Correlation Const. + Demographics Incl.')\n",
    "plt.fill_between(np.arange(1000)*500, yDyC_mean-yDyC_std, yDyC_mean+yDyC_std, color=colors_comp[3], alpha=0.3)\n",
    "\n",
    "plt.title(f'{arch.upper()} Policy Comparison between Training Settings', fontsize=18)\n",
    "plt.xlabel(\"Iterations\", fontsize=16)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.ylabel(\"WIS Return\", fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.ylim([0.2, 1.0])\n",
    "plt.ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0))\n",
    "plt.legend(loc=2,fontsize=14)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dst_pol_mean = np.copy(nDnC_mean)\n",
    "best_dst_pol_std = np.copy(nDnC_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Neural Network (RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'rnn'\n",
    "\n",
    "noDem_noCorr_dir = f'{arch}_noCntxt_s64_l1e-4_rand'\n",
    "yDem_noCorr_dir = f'{arch}_s64_l1e-4_rand'\n",
    "noDem_yCorr_dir = f'{arch}_corrConst_noCntxt_s64_l1e-4_rand'\n",
    "yDem_yCorr_dir = f'{arch}_corrConst_s128_l1e-4_rand'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_noDem_noCorr_pol_results = np.zeros((len(learning_rates),len(rand_nums), 1000))\n",
    "rnn_yDem_noCorr_pol_results = np.zeros((len(learning_rates),len(rand_nums), 1000))\n",
    "rnn_noDem_yCorr_pol_results = np.zeros((len(learning_rates),len(rand_nums), 1000))\n",
    "rnn_yDem_yCorr_pol_results = np.zeros((len(learning_rates),len(rand_nums), 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in learning_rates:\n",
    "    for rn in rand_nums:\n",
    "        lr_idx = learning_rates.index(lr)\n",
    "        rn_idx = rand_nums.index(rn)\n",
    "        nDnC_file_name = storage_dir_TWK+noDem_noCorr_dir+f'{rn}_sepsis/{arch}_data/'+pol_eval_file+f'{lr}.npy'\n",
    "        yDnC_file_name = storage_dir_TWK+yDem_noCorr_dir+f'{rn}_sepsis/{arch}_data/'+pol_eval_file+f'{lr}.npy'\n",
    "        nDyC_file_name = storage_dir_TWK+noDem_yCorr_dir+f'{rn}_sepsis/{arch}_data/'+pol_eval_file+f'{lr}.npy'\n",
    "        yDyC_file_name = storage_dir_TWK+yDem_yCorr_dir+f'{rn}_sepsis/{arch}_data/'+pol_eval_file+f'{lr}.npy'\n",
    "        \n",
    "        rnn_noDem_noCorr_pol_results[lr_idx, rn_idx,:] = ewma_vectorized(np.load(nDnC_file_name), alpha_param)\n",
    "        rnn_yDem_noCorr_pol_results[lr_idx, rn_idx,:] = ewma_vectorized(np.load(yDnC_file_name), alpha_param)\n",
    "        rnn_noDem_yCorr_pol_results[lr_idx, rn_idx,:] = ewma_vectorized(np.load(nDyC_file_name), alpha_param)\n",
    "        rnn_yDem_yCorr_pol_results[lr_idx, rn_idx,:] = ewma_vectorized(np.load(yDyC_file_name), alpha_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for lr_idx, lr in enumerate(learning_rates):\n",
    "    \n",
    "    temp_mean = np.mean(rnn_yDem_noCorr_pol_results[lr_idx], axis=0)\n",
    "    temp_std = np.std(rnn_yDem_noCorr_pol_results[lr_idx], axis=0)\n",
    "    \n",
    "    plt.plot(np.arange(1000), temp_mean, lw=2, color=colors[lr_idx], label=f'lr={lr}')\n",
    "    plt.fill_between(np.arange(1000),temp_mean - temp_std, temp_mean + temp_std, alpha=0.3, color=colors[lr_idx])\n",
    "plt.title(f'{arch.upper()} w/ Dem. w/o Corr')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for lr_idx, lr in enumerate(learning_rates):\n",
    "    \n",
    "    temp_mean = np.mean(rnn_noDem_yCorr_pol_results[lr_idx], axis=0)\n",
    "    temp_std = np.std(rnn_noDem_yCorr_pol_results[lr_idx], axis=0)\n",
    "    \n",
    "    plt.plot(np.arange(1000), temp_mean, lw=2, color=colors[lr_idx], label=f'lr={lr}')\n",
    "    plt.fill_between(np.arange(1000),temp_mean - temp_std, temp_mean + temp_std, alpha=0.3, color=colors[lr_idx])\n",
    "plt.title(f'{arch.upper()} w/o Dem. w/ Corr')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for lr_idx, lr in enumerate(learning_rates):\n",
    "    \n",
    "    temp_mean = np.mean(rnn_yDem_yCorr_pol_results[lr_idx], axis=0)\n",
    "    temp_std = np.std(rnn_yDem_yCorr_pol_results[lr_idx], axis=0)\n",
    "    \n",
    "    plt.plot(np.arange(1000), temp_mean, lw=2, color=colors[lr_idx], label=f'lr={lr}')\n",
    "    plt.fill_between(np.arange(1000),temp_mean - temp_std, temp_mean + temp_std, alpha=0.3, color=colors[lr_idx])\n",
    "plt.title(f'{arch.upper()} w/ Dem. w/ Corr')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for lr_idx, lr in enumerate(learning_rates):\n",
    "    \n",
    "    temp_mean = np.mean(rnn_noDem_noCorr_pol_results[lr_idx], axis=0)\n",
    "    temp_std = np.std(rnn_noDem_noCorr_pol_results[lr_idx], axis=0)\n",
    "    \n",
    "    plt.plot(np.arange(1000), temp_mean, lw=2, color=colors[lr_idx], label=f'lr={lr}')\n",
    "    plt.fill_between(np.arange(1000),temp_mean - temp_std, temp_mean + temp_std, alpha=0.3, color=colors[lr_idx])\n",
    "plt.title(f'{arch.upper()} w/o Dem. w/o Corr')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the policies learned between different training settings with a learning rate of 1e-3\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "nDnC_mean, nDnC_std = np.mean(rnn_noDem_noCorr_pol_results[-1], axis=0), np.std(rnn_noDem_noCorr_pol_results[-1], axis=0)\n",
    "nDyC_mean, nDyC_std = np.mean(rnn_noDem_yCorr_pol_results[-1], axis=0), np.std(rnn_noDem_yCorr_pol_results[-1], axis=0)\n",
    "yDnC_mean, yDnC_std = np.mean(rnn_yDem_noCorr_pol_results[-1], axis=0), np.std(rnn_yDem_noCorr_pol_results[-1], axis=0)\n",
    "yDyC_mean, yDyC_std = np.mean(rnn_yDem_yCorr_pol_results[-1], axis=0), np.std(rnn_yDem_yCorr_pol_results[-1], axis=0)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, nDnC_mean, lw=3, color=colors_comp[0], label='Observations Only')\n",
    "plt.fill_between(np.arange(1000)*500, nDnC_mean-nDnC_std, nDnC_mean+nDnC_std, color=colors_comp[0], alpha=0.3)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, nDyC_mean, lw=3, color=colors_comp[1], label='Correlation Constrained')\n",
    "plt.fill_between(np.arange(1000)*500, nDyC_mean-nDyC_std, nDyC_mean+nDyC_std, color=colors_comp[1], alpha=0.3)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, yDnC_mean, lw=3, color=colors_comp[2], label='Demographics Included')\n",
    "plt.fill_between(np.arange(1000)*500, yDnC_mean-yDnC_std, yDnC_mean+yDnC_std, color=colors_comp[2], alpha=0.3)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, yDyC_mean, lw=3, color=colors_comp[3], label='Correlation Const. + Demographics Incl.')\n",
    "plt.fill_between(np.arange(1000)*500, yDyC_mean-yDyC_std, yDyC_mean+yDyC_std, color=colors_comp[3], alpha=0.3)\n",
    "\n",
    "plt.title(f'{arch.upper()} Policy Comparison between Training Settings', fontsize=18)\n",
    "plt.xlabel(\"Iterations\", fontsize=16)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.ylabel(\"WIS Return\", fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.ylim([0.2, 1.0])\n",
    "plt.ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0))\n",
    "plt.legend(loc=2,fontsize=14)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rnn_pol_mean = np.copy(yDnC_mean)\n",
    "best_rnn_pol_std = np.copy(yDnC_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ODE-RNN (ODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'odernn'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ode_noDem_noCorr_pol_results = np.zeros((len(learning_rates),len(rand_nums), 1000))\n",
    "ode_yDem_noCorr_pol_results = np.zeros((len(learning_rates),len(rand_nums), 1000))\n",
    "ode_noDem_yCorr_pol_results = np.zeros((len(learning_rates),len(rand_nums), 1000))\n",
    "ode_yDem_yCorr_pol_results = np.zeros((len(learning_rates),len(rand_nums), 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in learning_rates:\n",
    "    for rn in rand_nums:\n",
    "        lr_idx = learning_rates.index(lr)\n",
    "        rn_idx = rand_nums.index(rn)\n",
    "        nDnC_file_name = storage_dir_HZ+f'{arch}/{arch}_sz64_rand{rn}_corr0_contextFalse_sepsis_training/{arch}_data/'+pol_eval_file+f'{lr}.npy'\n",
    "        yDnC_file_name = storage_dir_HZ+f'{arch}/{arch}_sz32_rand{rn}_corr0_contextTrue_sepsis_training/{arch}_data/'+pol_eval_file+f'{lr}.npy'\n",
    "        nDyC_file_name = storage_dir_HZ+f'{arch}/{arch}_sz64_rand{rn}_corr1_contextFalse_sepsis_training/{arch}_data/'+pol_eval_file+f'{lr}.npy'\n",
    "        yDyC_file_name = storage_dir_HZ+f'{arch}/{arch}_sz128_rand{rn}_corr1_contextTrue_sepsis_training/{arch}_data/'+pol_eval_file+f'{lr}.npy'\n",
    "        \n",
    "        ode_noDem_noCorr_pol_results[lr_idx, rn_idx,:] = ewma_vectorized(np.load(nDnC_file_name), alpha_param)\n",
    "        ode_yDem_noCorr_pol_results[lr_idx, rn_idx,:] = ewma_vectorized(np.load(yDnC_file_name), alpha_param)\n",
    "        ode_noDem_yCorr_pol_results[lr_idx, rn_idx,:] = ewma_vectorized(np.load(nDyC_file_name), alpha_param)\n",
    "        ode_yDem_yCorr_pol_results[lr_idx, rn_idx,:] = ewma_vectorized(np.load(yDyC_file_name), alpha_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for lr_idx, lr in enumerate(learning_rates):\n",
    "    \n",
    "    temp_mean = np.mean(ode_yDem_noCorr_pol_results[lr_idx], axis=0)\n",
    "    temp_std = np.std(ode_yDem_noCorr_pol_results[lr_idx], axis=0)\n",
    "    \n",
    "    plt.plot(np.arange(1000), temp_mean, lw=2, color=colors[lr_idx], label=f'lr={lr}')\n",
    "    plt.fill_between(np.arange(1000),temp_mean - temp_std, temp_mean + temp_std, alpha=0.3, color=colors[lr_idx])\n",
    "plt.title(f'{arch.upper()} w/ Dem. w/o Corr')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for lr_idx, lr in enumerate(learning_rates):\n",
    "    \n",
    "    temp_mean = np.mean(ode_noDem_yCorr_pol_results[lr_idx], axis=0)\n",
    "    temp_std = np.std(ode_noDem_yCorr_pol_results[lr_idx], axis=0)\n",
    "    \n",
    "    plt.plot(np.arange(1000), temp_mean, lw=2, color=colors[lr_idx], label=f'lr={lr}')\n",
    "    plt.fill_between(np.arange(1000),temp_mean - temp_std, temp_mean + temp_std, alpha=0.3, color=colors[lr_idx])\n",
    "plt.title(f'{arch.upper()} w/o Dem. w/ Corr')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for lr_idx, lr in enumerate(learning_rates):\n",
    "    \n",
    "    temp_mean = np.mean(ode_yDem_yCorr_pol_results[lr_idx], axis=0)\n",
    "    temp_std = np.std(ode_yDem_yCorr_pol_results[lr_idx], axis=0)\n",
    "    \n",
    "    plt.plot(np.arange(1000), temp_mean, lw=2, color=colors[lr_idx], label=f'lr={lr}')\n",
    "    plt.fill_between(np.arange(1000),temp_mean - temp_std, temp_mean + temp_std, alpha=0.3, color=colors[lr_idx])\n",
    "plt.title(f'{arch.upper()} w/ Dem. w/ Corr')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for lr_idx, lr in enumerate(learning_rates):\n",
    "    \n",
    "    temp_mean = np.mean(ode_noDem_noCorr_pol_results[lr_idx], axis=0)\n",
    "    temp_std = np.std(ode_noDem_noCorr_pol_results[lr_idx], axis=0)\n",
    "    \n",
    "    plt.plot(np.arange(1000), temp_mean, lw=2, color=colors[lr_idx], label=f'lr={lr}')\n",
    "    plt.fill_between(np.arange(1000),temp_mean - temp_std, temp_mean + temp_std, alpha=0.3, color=colors[lr_idx])\n",
    "plt.title(f'{arch.upper()} w/o Dem. w/o Corr')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the policies learned between different training settings with a learning rate of 1e-3\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "nDnC_mean, nDnC_std = np.mean(ode_noDem_noCorr_pol_results[-1], axis=0), np.std(ode_noDem_noCorr_pol_results[-1], axis=0)\n",
    "nDyC_mean, nDyC_std = np.mean(ode_noDem_yCorr_pol_results[-1], axis=0), np.std(ode_noDem_yCorr_pol_results[-1], axis=0)\n",
    "yDnC_mean, yDnC_std = np.mean(ode_yDem_noCorr_pol_results[-1], axis=0), np.std(ode_yDem_noCorr_pol_results[-1], axis=0)\n",
    "yDyC_mean, yDyC_std = np.mean(ode_yDem_yCorr_pol_results[-1], axis=0), np.std(ode_yDem_yCorr_pol_results[-1], axis=0)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, nDnC_mean, lw=3, color=colors_comp[0], label='Observations Only')\n",
    "plt.fill_between(np.arange(1000)*500, nDnC_mean-nDnC_std, nDnC_mean+nDnC_std, color=colors_comp[0], alpha=0.3)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, nDyC_mean, lw=3, color=colors_comp[1], label='Correlation Constrained')\n",
    "plt.fill_between(np.arange(1000)*500, nDyC_mean-nDyC_std, nDyC_mean+nDyC_std, color=colors_comp[1], alpha=0.3)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, yDnC_mean, lw=3, color=colors_comp[2], label='Demographics Included')\n",
    "plt.fill_between(np.arange(1000)*500, yDnC_mean-yDnC_std, yDnC_mean+yDnC_std, color=colors_comp[2], alpha=0.3)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, yDyC_mean, lw=3, color=colors_comp[3], label='Correlation Const. + Demographics Incl.')\n",
    "plt.fill_between(np.arange(1000)*500, yDyC_mean-yDyC_std, yDyC_mean+yDyC_std, color=colors_comp[3], alpha=0.3)\n",
    "\n",
    "plt.title(f'{arch.upper()} Policy Comparison between Training Settings', fontsize=18)\n",
    "plt.xlabel(\"Iterations\", fontsize=16)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.ylabel(\"WIS Return\", fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.ylim([0.2, 1.0])\n",
    "plt.ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0))\n",
    "plt.legend(loc=2,fontsize=14)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ode_pol_mean = np.copy(nDnC_mean)\n",
    "best_ode_pol_std = np.copy(nDnC_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural CDE (CDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'cde'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cde_noDem_noCorr_pol_results = np.zeros((len(learning_rates),len(rand_nums), 1000))\n",
    "cde_yDem_noCorr_pol_results = np.zeros((len(learning_rates),len(rand_nums), 1000))\n",
    "cde_noDem_yCorr_pol_results = np.zeros((len(learning_rates),len(rand_nums), 1000))\n",
    "cde_yDem_yCorr_pol_results = np.zeros((len(learning_rates),len(rand_nums), 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in learning_rates:\n",
    "    for rn in rand_nums:\n",
    "        lr_idx = learning_rates.index(lr)\n",
    "        rn_idx = rand_nums.index(rn)\n",
    "        nDnC_file_name = storage_dir_HZ+f'{arch}/{arch}_sz64_rand{rn}_corr0_contextFalse_sepsis_training/{arch}_data/'+pol_eval_file+f'{lr}.npy'\n",
    "        yDnC_file_name = storage_dir_HZ+f'{arch}/{arch}_sz32_rand{rn}_corr0_contextTrue_sepsis_training/{arch}_data/'+pol_eval_file+f'{lr}.npy'\n",
    "        nDyC_file_name = storage_dir_HZ+f'{arch}/{arch}_sz32_rand{rn}_corr1_contextFalse_sepsis_training/{arch}_data/'+pol_eval_file+f'{lr}.npy'\n",
    "        yDyC_file_name = storage_dir_HZ+f'{arch}/{arch}_sz128_rand{rn}_corr1_contextTrue_sepsis_training/{arch}_data/'+pol_eval_file+f'{lr}.npy'\n",
    "        \n",
    "        cde_noDem_noCorr_pol_results[lr_idx, rn_idx,:] = ewma_vectorized(np.load(nDnC_file_name), alpha_param)\n",
    "        cde_yDem_noCorr_pol_results[lr_idx, rn_idx,:] = ewma_vectorized(np.load(yDnC_file_name), alpha_param)\n",
    "        cde_noDem_yCorr_pol_results[lr_idx, rn_idx,:] = ewma_vectorized(np.load(nDyC_file_name), alpha_param)\n",
    "        cde_yDem_yCorr_pol_results[lr_idx, rn_idx,:] = ewma_vectorized(np.load(yDyC_file_name), alpha_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for lr_idx, lr in enumerate(learning_rates):\n",
    "    \n",
    "    temp_mean = np.mean(cde_yDem_noCorr_pol_results[lr_idx], axis=0)\n",
    "    temp_std = np.std(cde_yDem_noCorr_pol_results[lr_idx], axis=0)\n",
    "    \n",
    "    plt.plot(np.arange(1000), temp_mean, lw=2, color=colors[lr_idx], label=f'lr={lr}')\n",
    "    plt.fill_between(np.arange(1000),temp_mean - temp_std, temp_mean + temp_std, alpha=0.3, color=colors[lr_idx])\n",
    "plt.title(f'{arch.upper()} w/ Dem. w/o Corr')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for lr_idx, lr in enumerate(learning_rates):\n",
    "    \n",
    "    temp_mean = np.mean(cde_noDem_yCorr_pol_results[lr_idx], axis=0)\n",
    "    temp_std = np.std(cde_noDem_yCorr_pol_results[lr_idx], axis=0)\n",
    "    \n",
    "    plt.plot(np.arange(1000), temp_mean, lw=2, color=colors[lr_idx], label=f'lr={lr}')\n",
    "    plt.fill_between(np.arange(1000),temp_mean - temp_std, temp_mean + temp_std, alpha=0.3, color=colors[lr_idx])\n",
    "plt.title(f'{arch.upper()} w/o Dem. w/ Corr')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for lr_idx, lr in enumerate(learning_rates):\n",
    "    \n",
    "    temp_mean = np.mean(cde_yDem_yCorr_pol_results[lr_idx], axis=0)\n",
    "    temp_std = np.std(cde_yDem_yCorr_pol_results[lr_idx], axis=0)\n",
    "    \n",
    "    plt.plot(np.arange(1000), temp_mean, lw=2, color=colors[lr_idx], label=f'lr={lr}')\n",
    "    plt.fill_between(np.arange(1000),temp_mean - temp_std, temp_mean + temp_std, alpha=0.3, color=colors[lr_idx])\n",
    "plt.title(f'{arch.upper()} w/ Dem. w/ Corr')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for lr_idx, lr in enumerate(learning_rates):\n",
    "    \n",
    "    temp_mean = np.mean(cde_noDem_noCorr_pol_results[lr_idx], axis=0)\n",
    "    temp_std = np.std(cde_noDem_noCorr_pol_results[lr_idx], axis=0)\n",
    "    \n",
    "    plt.plot(np.arange(1000), temp_mean, lw=2, color=colors[lr_idx], label=f'lr={lr}')\n",
    "    plt.fill_between(np.arange(1000),temp_mean - temp_std, temp_mean + temp_std, alpha=0.3, color=colors[lr_idx])\n",
    "plt.title(f'{arch.upper()} w/o Dem. w/o Corr')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the policies learned between different training settings with a learning rate of 1e-3\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "nDnC_mean, nDnC_std = np.mean(cde_noDem_noCorr_pol_results[-1], axis=0), np.std(cde_noDem_noCorr_pol_results[0], axis=0)\n",
    "nDyC_mean, nDyC_std = np.mean(cde_noDem_yCorr_pol_results[-1], axis=0), np.std(cde_noDem_yCorr_pol_results[-1], axis=0)\n",
    "yDnC_mean, yDnC_std = np.mean(cde_yDem_noCorr_pol_results[0], axis=0), np.std(cde_yDem_noCorr_pol_results[0], axis=0)\n",
    "yDyC_mean, yDyC_std = np.mean(cde_yDem_yCorr_pol_results[-1], axis=0), np.std(cde_yDem_yCorr_pol_results[-1], axis=0)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, nDnC_mean, lw=3, color=colors_comp[0], label='Observations Only')\n",
    "plt.fill_between(np.arange(1000)*500, nDnC_mean-nDnC_std, nDnC_mean+nDnC_std, color=colors_comp[0], alpha=0.3)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, nDyC_mean, lw=3, color=colors_comp[1], label='Correlation Constrained')\n",
    "plt.fill_between(np.arange(1000)*500, nDyC_mean-nDyC_std, nDyC_mean+nDyC_std, color=colors_comp[1], alpha=0.3)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, yDnC_mean, lw=3, color=colors_comp[2], label='Demographics Included')\n",
    "plt.fill_between(np.arange(1000)*500, yDnC_mean-yDnC_std, yDnC_mean+yDnC_std, color=colors_comp[2], alpha=0.3)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, yDyC_mean, lw=3, color=colors_comp[3], label='Correlation Const. + Demographics Incl.')\n",
    "plt.fill_between(np.arange(1000)*500, yDyC_mean-yDyC_std, yDyC_mean+yDyC_std, color=colors_comp[3], alpha=0.3)\n",
    "\n",
    "plt.title(f'{arch.upper()} Policy Comparison between Training Settings', fontsize=18)\n",
    "plt.xlabel(\"Iterations\", fontsize=16)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.ylabel(\"WIS Return\", fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.ylim([0.2, 1.0])\n",
    "plt.ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0))\n",
    "plt.legend(loc=2,fontsize=14)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cde_pol_mean = np.copy(nDnC_mean)\n",
    "best_cde_pol_std = np.copy(nDnC_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOW PUTTING THEM ALL TOGETHER!!! :) :) ;) :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archs = ['ae','ais','cde','ddm','dst','ode','rnn']\n",
    "flatui = [\"#9b59b6\", \"#3498db\", \"#feb308\", \"#e74c3c\", \"#34495e\", \"#2ecc71\", \"#84543f\", \"#76852a\"]\n",
    "colors = sns.color_palette(flatui,7)\n",
    "# colors = sns.color_palette('tab10',len(archs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the policies learned between SRL approaches...\n",
    "plt.figure(figsize=(16,12))\n",
    "\n",
    "plt.plot(np.arange(1000)*500, best_ae_pol_mean, lw=3, color=colors[0], label='AE')\n",
    "plt.fill_between(np.arange(1000)*500, best_ae_pol_mean-best_ae_pol_std, best_ae_pol_mean+best_ae_pol_std, color=colors[0], alpha=0.3)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, best_ais_pol_mean, lw=3, color=colors[1], label='AIS')\n",
    "plt.fill_between(np.arange(1000)*500, best_ais_pol_mean-best_ais_pol_std, best_ais_pol_mean+best_ais_pol_std, color=colors[1], alpha=0.3)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, best_cde_pol_mean, lw=3, color=colors[2], label='CDE')\n",
    "plt.fill_between(np.arange(1000)*500, best_cde_pol_mean-best_cde_pol_std, best_cde_pol_mean+best_cde_pol_std, color=colors[2], alpha=0.3)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, best_dst_pol_mean, lw=3, color=colors[3], label='DST')\n",
    "plt.fill_between(np.arange(1000)*500, best_dst_pol_mean-best_dst_pol_std, best_dst_pol_mean+best_dst_pol_std, color=colors[3], alpha=0.3)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, best_ddm_pol_mean, lw=3, color=colors[4], label='DDM')\n",
    "plt.fill_between(np.arange(1000)*500, best_ddm_pol_mean-best_ddm_pol_std, best_ddm_pol_mean+best_ddm_pol_std, color=colors[4], alpha=0.3)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, best_ode_pol_mean, lw=3, color=colors[5], label='ODE')\n",
    "plt.fill_between(np.arange(1000)*500, best_ode_pol_mean-best_ode_pol_std, best_ode_pol_mean+best_ode_pol_std, color=colors[5], alpha=0.3)\n",
    "\n",
    "plt.plot(np.arange(1000)*500, best_rnn_pol_mean, lw=3, color=colors[6], label='RNN')\n",
    "plt.fill_between(np.arange(1000)*500, best_rnn_pol_mean-best_rnn_pol_std, best_rnn_pol_mean+best_rnn_pol_std, color=colors[6], alpha=0.3)\n",
    "\n",
    "\n",
    "# plt.title('Policy Comparison between Embedding Approaches', fontsize=18)\n",
    "plt.xlabel(\"Iterations\", fontsize=24)\n",
    "plt.ylabel(\"WIS Return\", fontsize=24)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.legend(loc=2,fontsize=18)\n",
    "plt.ylim([0.2, 1.0])\n",
    "plt.grid()\n",
    "plt.xticks(fontsize=20)\n",
    "plt.ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
